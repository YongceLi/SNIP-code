{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7f3979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "tqdm.pandas(desc=\"Processing\")\n",
    "\n",
    "client = OpenAI()\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74208362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read neuron explanations\n",
    "with open('neuron_explanation_gpt2_small.pkl', 'rb') as file:\n",
    "    neuron_explanation_gpt2_small = pickle.load(file)\n",
    "sorted_neuron_explanation = sorted(neuron_explanation_gpt2_small, key=lambda x: x[-1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b237fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to pandas df\n",
    "neuron_explanation_df = pd.DataFrame(sorted_neuron_explanation, columns=['layer_id', 'neuron_id', 'explanation', 'explanation score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b4aced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose neurons with explanation score greater than a threshold, ensuring it's well explained.\n",
    "top_10_percent = neuron_explanation_df[neuron_explanation_df[\"explanation score\"] > 0.53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ab1a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get concept embedding for each neuron\n",
    "top_10_percent['ada_embedding'] = top_10_percent['explanation'].progress_apply(lambda x: get_embedding(x, model='text-embedding-3-small'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8feee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.vstack(top_10_percent.ada_embedding.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adae199",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3176166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset concepts embedding\n",
    "with open('data/CBT_V_concepts_embedding.pkl', 'rb') as file:\n",
    "    CBT_V_embedding = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bff9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    similarity = dot_product / (norm_vec1 * norm_vec2)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cd8bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate similarity score according to neuron and dataset concept embeddings\n",
    "similarity_score = []\n",
    "ind = []\n",
    "for i in range(embedding_matrix.shape[0]):\n",
    "    curr_max = 0\n",
    "    curr_ind = 0\n",
    "    for j in range(CBT_V_embedding.T.shape[1]):\n",
    "        sim = cosine_similarity(embedding_matrix[i], CBT_V_embedding.T[:,j])\n",
    "        if sim > curr_max:\n",
    "            curr_ind = j\n",
    "        curr_max = max(curr_max, sim)\n",
    "    ind.append(curr_ind)\n",
    "    similarity_score.append(curr_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97adffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_percent[\"similarity\"] = similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217be817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort neurons based on their importance score\n",
    "sorted_top_10_percent = top_10_percent.sort_values(by='similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0def26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create neuron prune dict based on selected neuron tuples\n",
    "def get_dict_from_tuples(tuples):\n",
    "    returned_dict = {}\n",
    "    for e in tuples:\n",
    "        layer_id = e[0]\n",
    "        neuron_id = e[1]\n",
    "        layer_name = f\"transformer.h.{layer_id}.mlp.act\"\n",
    "        if layer_name in returned_dict:\n",
    "            returned_dict[layer_name].append(e[1])\n",
    "        else:\n",
    "            returned_dict[layer_name] = [e[1]]\n",
    "    return returned_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e387eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select top k neurons, create tuples list\n",
    "k = 1000\n",
    "tuple_list = []\n",
    "for i in range(k):\n",
    "    tuple_list.append((sorted_top_10_percent.iloc[i][\"layer_id\"], sorted_top_10_percent.iloc[i][\"neuron_id\"]))\n",
    "\n",
    "with open(f'SNIP_CBT_V_top_{k}.pkl', 'wb') as file:\n",
    "    pickle.dump(get_dict_from_tuples(tuple_list), file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
